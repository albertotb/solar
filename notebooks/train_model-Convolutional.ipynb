{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build train and test matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "\n",
    "df = (feather.read_dataframe('/home/SHARED/SOLAR/data/oahu_min.feather')\n",
    "             .set_index('Datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/15722324/sliding-window-in-numpy\n",
    "def window_stack_forward(a, stepsize=1, width=3):\n",
    "    return np.hstack( a[i:1+i-width or None:stepsize] for i in range(0, width) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I feel this function can also be done for pd.DataFrame\n",
    "def window_stack(a, width=3):\n",
    "    n = a.shape[0]\n",
    "    return np.hstack(list(a[(width-1-i):(n-i)] for i in range(0, width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In pandas 0.24, use df.to_numpy() instead of df.values. Also care with non-numeric columns\n",
    "width = 61\n",
    "a = window_stack(df.values, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "times   = [ ('t' if not idx else 't-{:d}'.format(idx)) for idx in range(width) ]\n",
    "columns = pd.MultiIndex.from_product((times, df.columns), names=('time', 'location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to DataFrame, just for convenience of having indexes\n",
    "df_roll = pd.DataFrame(a, index=df.index[width-1:], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split target (time t) and variables (times t-1 to t-width+1)\n",
    "y = df_roll['t']\n",
    "X = df_roll.drop(columns='t', level='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test, approximately 12 and 4 months respectively\n",
    "X_train, X_test = X[:'2011-07-31'], X['2011-08-01':]\n",
    "y_train, y_test = y[:'2011-07-31'], y['2011-08-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(449885, 1140)\n",
      "(82892, 1140)\n",
      "(449885, 19)\n",
      "(82892, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional predictor\n",
    "\n",
    "First we preprocess the dataset (for the moment, we'll just use as features the t-1 values at each sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use the previous timestep as features\n",
    "X_tr1 = X_train['t-1']\n",
    "y_tr1 = y_train\n",
    "\n",
    "X_te1 = X_test['t-1']\n",
    "y_te1 = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to use a 1D convolution, we are going to sort the sensors. For the initial test, we'll just sort them by longitude (from East to West). That way, nearer sensors are in close positions in the tensor, so the 1D convolution may extract useful correlations.\n",
    "\n",
    "Note: many other possible ordenations of the sensors could be added as new channels in the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# We load the info of the sensors to extract the longitude information\n",
    "info = pd.read_csv('/home/SHARED/SOLAR/data/info.csv')\n",
    "\n",
    "info.Location = info.Location.apply(lambda x: (x[:2] + x[-2:]).replace('_', ''))\n",
    "info.index = info.Location\n",
    "# Sorted longitudes\n",
    "longs = info['       Longitude'].sort_values(ascending=False)\n",
    "\n",
    "# We drop two sensors (they are different compared to the other 17, since they are \"tilted\")\n",
    "X_tr1.drop('GT_AP6', inplace=True, axis=1)\n",
    "y_tr1.drop('GT_AP6', inplace=True, axis=1)\n",
    "X_tr1.drop('GT_DH1', inplace=True, axis=1)\n",
    "y_tr1.drop('GT_DH1', inplace=True, axis=1)\n",
    "X_te1.drop('GT_AP6', inplace=True, axis=1)\n",
    "y_te1.drop('GT_AP6', inplace=True, axis=1)\n",
    "X_te1.drop('GT_DH1', inplace=True, axis=1)\n",
    "y_te1.drop('GT_DH1', inplace=True, axis=1)\n",
    "\n",
    "# Just some auxiliar code to homogeneize name of sensors across different tables\n",
    "homogen_name = lambda x: x[-4:].replace('_', '')\n",
    "X_tr1.columns = [homogen_name(x) for x in X_tr1.columns.values.tolist()]\n",
    "y_tr1.columns = [homogen_name(x) for x in y_tr1.columns.values.tolist()]\n",
    "X_te1.columns = [homogen_name(x) for x in X_te1.columns.values.tolist()]\n",
    "y_te1.columns = [homogen_name(x) for x in y_te1.columns.values.tolist()]\n",
    "\n",
    "\n",
    "# Finally, we sort the data according to sensor's longitude\n",
    "X_tr1_1 = X_tr1[longs.index]\n",
    "y_tr1_1 = y_tr1[longs.index]\n",
    "X_te1_1 = X_te1[longs.index]\n",
    "y_te1_1 = y_te1[longs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify which sensor do we want to predict and test.\n",
    "\n",
    "(In the future, we need to discuss how are we going to predict, if just by looping over each sensor, or just give a vectorial prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sensors = 17\n",
    "sensor = 'AP5'  # 'AP5' initial\n",
    "index_sensor = 4\n",
    "\n",
    "X_tr1_1_np = X_tr1_1.values\n",
    "y_tr1_1_np = y_tr1_1[sensor].values\n",
    "\n",
    "X_te1_1_np = X_te1_1.values\n",
    "y_te1_1_np = y_te1_1[sensor].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape, Add, Multiply, Subtract, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, LocallyConnected1D, Conv1D, UpSampling1D, MaxPooling1D, Dot, Concatenate\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture is defined below.\n",
    "\n",
    "Some highlights:\n",
    "* Locally connected works better than pure convolutional at the first layers (probably because the sensors at not located in a uniform grid)\n",
    "* Trick to improve acc: add a final layer combining the convolutional prediction with the persistance prediction, so in case the input is \"strange\", the model could learn to output the persistance prediction (i.e., the previous time-step), which is somewhat reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(n_sensors,1), name='main_input')\n",
    "x = LocallyConnected1D(8, 7, data_format = 'channels_last', padding='valid')(xin)\n",
    "x = Activation('relu')(x)\n",
    "x = LocallyConnected1D(16, 5, data_format = 'channels_last', padding='valid')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv1D(32, 3, data_format = 'channels_last', padding='causal')(x)\n",
    "xl = Flatten()(x)\n",
    "xl = Dropout(0.2)(xl)\n",
    "xo = Dense(1)(xl)\n",
    "\n",
    "# use date info here?\n",
    "xinf = Flatten()(xin)\n",
    "s  = Dense(5)(xinf)\n",
    "s = Activation('tanh')(s)\n",
    "s = Dense(2)(s)\n",
    "s = Activation('softmax')(s)\n",
    "\n",
    "\n",
    "xin_0 = Activation('relu')(xin)\n",
    "xin_1 = Lambda(lambda x : x[:,index_sensor,:])(xin_0)\n",
    "xo_m = Dot(axes=1)([Concatenate()([xo,xin_1]), s])\n",
    "# instead of this, use a residual connection\n",
    "\n",
    "#xom = Add()([xo, xin_1])\n",
    "\n",
    "# better than just residual (xom)\n",
    "xo_m = Activation('relu')(xo_m)\n",
    "\n",
    "model = Model(inputs=[xin], outputs=[xo_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a callback to log metrics and another one to schedule the learning rate\n",
    "\n",
    "#see clr.py in this same folder\n",
    "from clr import CyclicLR\n",
    "\n",
    "c1 = keras.callbacks.BaseLogger(stateful_metrics=None)\n",
    "c2 = CyclicLR(step_size=250, base_lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train. The below configuration should take 2 minutes in a 16 core CPU\n",
    "(no GPU needed). We are using a huge batch-size to speed up things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 449885 samples, validate on 82892 samples\n",
      "Epoch 1/32\n",
      "449885/449885 [==============================] - 5s 11us/step - loss: 75.3394 - val_loss: 43.7564\n",
      "Epoch 2/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 47.3244 - val_loss: 41.6816\n",
      "Epoch 3/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 46.2087 - val_loss: 42.4307\n",
      "Epoch 4/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 45.6312 - val_loss: 41.5193\n",
      "Epoch 5/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.7380 - val_loss: 40.8821\n",
      "Epoch 6/32\n",
      "449885/449885 [==============================] - 3s 7us/step - loss: 44.7980 - val_loss: 40.7858\n",
      "Epoch 7/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.3416 - val_loss: 40.7110\n",
      "Epoch 8/32\n",
      "449885/449885 [==============================] - 3s 7us/step - loss: 44.3976 - val_loss: 41.0561\n",
      "Epoch 9/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.2570 - val_loss: 40.6462\n",
      "Epoch 10/32\n",
      "449885/449885 [==============================] - 3s 7us/step - loss: 44.1274 - val_loss: 40.7764\n",
      "Epoch 11/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.1442 - val_loss: 40.8304\n",
      "Epoch 12/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.9331 - val_loss: 40.7790\n",
      "Epoch 13/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.1908 - val_loss: 41.1085\n",
      "Epoch 14/32\n",
      "449885/449885 [==============================] - 3s 7us/step - loss: 43.8935 - val_loss: 40.8004\n",
      "Epoch 15/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 44.0322 - val_loss: 41.2421\n",
      "Epoch 16/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.8630 - val_loss: 40.8032\n",
      "Epoch 17/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.8563 - val_loss: 41.6479\n",
      "Epoch 18/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.8641 - val_loss: 40.7089\n",
      "Epoch 19/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.7138 - val_loss: 40.9168\n",
      "Epoch 20/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.8119 - val_loss: 40.4513\n",
      "Epoch 21/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.5866 - val_loss: 40.7716\n",
      "Epoch 22/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.8473 - val_loss: 40.6285\n",
      "Epoch 23/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.5336 - val_loss: 40.5671\n",
      "Epoch 24/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.6861 - val_loss: 40.8101\n",
      "Epoch 25/32\n",
      "449885/449885 [==============================] - 4s 8us/step - loss: 43.5448 - val_loss: 40.1878\n",
      "Epoch 26/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.5263 - val_loss: 40.7839\n",
      "Epoch 27/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.6614 - val_loss: 40.2880\n",
      "Epoch 28/32\n",
      "449885/449885 [==============================] - 4s 8us/step - loss: 43.4126 - val_loss: 40.4426\n",
      "Epoch 29/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.6215 - val_loss: 40.3123\n",
      "Epoch 30/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.3569 - val_loss: 40.2279\n",
      "Epoch 31/32\n",
      "449885/449885 [==============================] - 3s 7us/step - loss: 43.6187 - val_loss: 40.4140\n",
      "Epoch 32/32\n",
      "449885/449885 [==============================] - 3s 8us/step - loss: 43.3724 - val_loss: 40.0894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffb1937c0b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1 << 11   # as big as possible so we can explore many models\n",
    "epochs = 1 << 5\n",
    "model.fit(np.atleast_3d(X_tr1_1_np), y_tr1_1_np, batch_size=batch_size, epochs=epochs, validation_data=\n",
    "          (np.atleast_3d(X_te1_1_np),y_te1_1_np), callbacks=[c1, c2])\n",
    "\n",
    "# Note: for this quick trial, we are using as validation the test!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final MAE for AP5 sensor is around 40.2\n",
    "# Other sensors are also around 40-50.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
