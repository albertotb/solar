{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build train and test matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Lambda\n",
    "from keras.layers import TimeDistributed, LocallyConnected1D, Conv1D, Concatenate, LSTM\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from utils.build_matrix import df_shift\n",
    "from utils.clr import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/SHARED/SOLAR/data/oahu_min_final.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_roll = df_shift(df, periods=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split target (time t) and variables (times t-1 to t-width+1)\n",
    "y = df_roll['t']\n",
    "X = df_roll.drop(columns='t', level='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split train-test, approximately 12 and 4 months respectively\n",
    "X_train, X_test = X[:'2011-07-31'], X['2011-08-01':]\n",
    "y_train, y_test = y[:'2011-07-31'], y['2011-08-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298595, 48)\n",
      "(55016, 48)\n",
      "(298595, 16)\n",
      "(55016, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to use a 1D convolution, we are going to sort the sensors. For the initial test, we'll just sort them by longitude (from East to West). That way, nearer sensors are in close positions in the tensor, so the 1D convolution may extract useful correlations.\n",
    "\n",
    "Note: many other possible ordenations of the sensors could be added as new channels in the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We load the info of the sensors to extract the longitude information\n",
    "info = pd.read_pickle('/home/SHARED/SOLAR/data/info.pkl')\n",
    "\n",
    "# Sorted longitudes\n",
    "lon = info['Longitude'].sort_values(ascending=False).drop('AP3')\n",
    "lat = info['Latitude'].sort_values(ascending=False).drop('AP3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_idx = lon.index.map(pd.Series(range(df.shape[1]), index=df.columns)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr1 = X_train.to_numpy().reshape(-1, 3, df.shape[1], 1)[:, :, lon_idx, :]\n",
    "y_tr1 = y_train.to_numpy()[:, lon_idx]\n",
    "\n",
    "X_te1 = X_test.to_numpy().reshape(-1, 3, df.shape[1], 1)[:, :, lon_idx, :]\n",
    "y_te1 = y_test.to_numpy()[:, lon_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify which sensor do we want to predict and test.\n",
    "\n",
    "(In the future, we need to discuss how are we going to predict, if just by looping over each sensor, or just give a vectorial prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture is defined below.\n",
    "\n",
    "Some highlights:\n",
    "* Locally connected works better than pure convolutional at the first layers (probably because the sensors at not located in a uniform grid)\n",
    "* Trick to improve acc: add a final layer combining the convolutional prediction with the persistance prediction, so in case the input is \"strange\", the model could learn to output the persistance prediction (i.e., the previous time-step), which is somewhat reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model_rnn(n_steps=3, n_sensors=16):\n",
    "    ''' Returns a model using all the sensors to predict index_sensor '''\n",
    "    xin = Input(shape=(n_steps, n_sensors, 1), name='main_input')\n",
    "    x = TimeDistributed(\n",
    "            LocallyConnected1D(8, 7,  data_format = 'channels_last', padding='valid', activation='relu')\n",
    "        )(xin)\n",
    "    x = TimeDistributed(\n",
    "            LocallyConnected1D(16, 5, data_format = 'channels_last', padding='valid', activation='relu')\n",
    "        )(x)\n",
    "    x = TimeDistributed(\n",
    "            Conv1D(32, 3, data_format = 'channels_last', padding='causal')\n",
    "        )(x)\n",
    "    xl = TimeDistributed(\n",
    "            Flatten()\n",
    "        )(x)\n",
    "    xl = LSTM(20)(xl)\n",
    "    xl = Dropout(0.2)(xl)\n",
    "    xo = Dense(n_sensors)(xl)\n",
    "\n",
    "    model = Model(inputs=[xin], outputs=[xo])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(batch_size, epochs, n_steps, n_sensors):\n",
    "    \n",
    "    lr = 0.0001\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    c1 = CyclicLR(step_size=250, base_lr=lr)\n",
    "    \n",
    "    # Validation using TS split (just to obtain different MAE estimations, no hyperoptimization for the moment)\n",
    "    cv_loss = []\n",
    "    for tr_idx, va_idx in TimeSeriesSplit(n_splits=5).split(X_tr1):\n",
    "        model = make_model_rnn(n_steps=n_steps, n_sensors=n_sensors)\n",
    "        model.compile(opt, loss='mean_absolute_error')\n",
    "        hist = model.fit(X_tr1[tr_idx], y_tr1[tr_idx], \n",
    "                         batch_size=batch_size, \n",
    "                         epochs=epochs, \n",
    "                         validation_data=(X_tr1[va_idx], y_tr1[va_idx]), \n",
    "                         callbacks=[c1], \n",
    "                         verbose=0)\n",
    "        cv_loss.append(hist.history['val_loss'][-1])\n",
    "    \n",
    "    # Testing\n",
    "    model = make_model_rnn(n_steps=n_steps, n_sensors=n_sensors)\n",
    "    model.compile(opt, loss='mean_absolute_error')\n",
    "    hist = model.fit(X_tr1, y_tr1, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              validation_data=(X_te1, y_te1), \n",
    "              callbacks=[c1], \n",
    "              verbose=0)\n",
    "    \n",
    "    test_loss = hist.history['val_loss'][-1]\n",
    "    \n",
    "    print('MAE_val ', cv_loss)\n",
    "    print('MAE_test ', test_loss)\n",
    "    \n",
    "    return test_loss, cv_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 3, 16, 1)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 3, 10, 8)          640       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 3, 6, 16)          3936      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 3, 6, 32)          1568      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 3, 192)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                17040     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                336       \n",
      "=================================================================\n",
      "Total params: 23,520\n",
      "Trainable params: 23,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model_rnn(n_steps=3, n_sensors=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train. The below configuration should take 2 minutes in a 16 core CPU\n",
    "(no GPU needed). We are using a huge batch-size to speed up things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_val  [0.11648415589942221, 0.08105337864483624, 0.041186277078846215, 0.06964156025545112, 0.1187103052485364]\n",
      "MAE_test  0.08772129851604801\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048   # as big as possible so we can explore many models\n",
    "epochs = 32\n",
    "\n",
    "_, _, model = train_and_test(batch_size, epochs, n_steps=3, n_sensors=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = pd.Series(np.mean(np.abs(model.predict(X_te1) - y_te1), axis=0), index=lon.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "DH10    0.073901\n",
       "DH11    0.074398\n",
       "AP5     0.076310\n",
       "DH9     0.076534\n",
       "DH8     0.078301\n",
       "DH6     0.078756\n",
       "DH4     0.080762\n",
       "DH3     0.082154\n",
       "AP1     0.085120\n",
       "DH7     0.085368\n",
       "DH5     0.089862\n",
       "DH2     0.091355\n",
       "DH1     0.095765\n",
       "AP4     0.099898\n",
       "AP6     0.107915\n",
       "AP7     0.127141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.087721298823349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
